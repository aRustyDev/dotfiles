---
services:
  # =============================================================================
  # Grafana Loki - Log Aggregation System
  # =============================================================================
  #
  # Loki is a horizontally scalable, highly available, multi-tenant log
  # aggregation system inspired by Prometheus. It indexes metadata (labels)
  # rather than log content, making it cost-effective and efficient.
  #
  # Features:
  #   - Label-based log indexing (like Prometheus for logs)
  #   - Native Grafana integration
  #   - LogQL query language
  #   - Multi-tenant support
  #   - S3/GCS/Azure blob storage support
  #
  # Endpoints:
  #   - Push: POST /loki/api/v1/push (for log ingestion)
  #   - Query: GET /loki/api/v1/query (for log queries)
  #   - Labels: GET /loki/api/v1/labels
  #   - Ready: GET /ready
  #
  # Usage:
  #   docker-compose -f loki.yaml up
  #   docker-compose --profile observability up
  #
  # =============================================================================

  loki:
    image: grafana/loki:3.0.0
    hostname: loki
    container_name: loki
    profiles: ["core", "o11y"]
    user: "10001:10001"
    networks:
      - backend # For service access
      - data-tier # For storage backends
    restart: unless-stopped
    command: -config.file=/etc/loki/loki.yaml
    volumes:
      - ${XDG_CONFIG_HOME:-$HOME/.config}/docker/config/loki:/etc/loki:ro
      - ${XDG_DATA_HOME:-$HOME/.local/share}/loki:/loki
    expose:
      - "3100" # HTTP API
      - "9096" # gRPC (for distributed mode)
    healthcheck:
      test:
        ["CMD-SHELL", "wget --spider -q http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 256M
  # =============================================================================
  # Grafana Mimir - Scalable Long-Term Metrics Storage
  # =============================================================================
  #
  # Mimir is an open-source, horizontally scalable, highly available, multi-tenant
  # TSDB for long-term storage of Prometheus metrics. It provides a Prometheus-
  # compatible query API with improved scalability.
  #
  # Features:
  #   - Horizontally scalable (handles billions of active series)
  #   - 100% Prometheus-compatible (remote_write & PromQL)
  #   - Multi-tenant by design
  #   - Long-term storage with compaction
  #   - High availability with replication
  #   - Native Grafana integration
  #
  # API Compatibility:
  #   - Remote Write: /api/v1/push
  #   - Query: /prometheus/api/v1/query
  #   - Query Range: /prometheus/api/v1/query_range
  #   - Series: /prometheus/api/v1/series
  #   - Labels: /prometheus/api/v1/labels
  #
  # Usage:
  #   docker-compose -f mimir.yaml up
  #   docker-compose --profile observability up
  #
  # =============================================================================
  mimir:
    image: grafana/mimir:2.12.0
    hostname: mimir
    container_name: mimir
    profiles: ["core", "o11y"]
    user: "10001:10001"
    networks:
      - backend # For service access
      - data-tier # For storage backends
    restart: unless-stopped
    command:
      - -config.file=/etc/mimir/mimir.yaml
      - -target=all
    volumes:
      - ${XDG_CONFIG_HOME:-$HOME/.config}/docker/config/mimir:/etc/mimir:ro
      - ${XDG_DATA_HOME:-$HOME/.local/share}/mimir:/data
    expose:
      - "9009" # HTTP API
      - "9095" # gRPC
    healthcheck:
      test:
        ["CMD-SHELL", "wget --spider -q http://localhost:9009/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 512M

  # =============================================================================
  # Grafana - Observability & Visualization Platform
  # =============================================================================
  #
  # Grafana is the open-source platform for monitoring and observability.
  # It allows you to query, visualize, alert on, and understand your metrics
  # no matter where they are stored.
  #
  # Features:
  #   - Unified dashboards for metrics, logs, and traces
  #   - Native support for Prometheus, Loki, Tempo, Mimir
  #   - Alerting with multiple notification channels
  #   - Data source plugins for 100+ backends
  #   - Dashboard provisioning via YAML
  #
  # Default Credentials:
  #   - Username: admin
  #   - Password: (set via GF_SECURITY_ADMIN_PASSWORD)
  #
  # Pre-configured Data Sources:
  #   - Prometheus (metrics)
  #   - Loki (logs)
  #   - Tempo (traces)
  #   - Mimir (long-term metrics)
  #   - Pyroscope (continuous profiling)
  #
  # Usage:
  #   docker-compose -f grafana.yaml up
  #   docker-compose --profile observability up
  #
  # =============================================================================

  grafana:
    image: grafana/grafana:11.0.0
    hostname: grafana
    container_name: grafana
    profiles: ["core", "o11y"]
    user: "472:472"
    networks:
      - frontend # Web UI access
      - backend # Connect to data sources
    restart: unless-stopped
    environment:
      # Security
      GF_SECURITY_ADMIN_USER: "${GRAFANA_ADMIN_USER:-op://Developer/Grafana/Admin/user}"
      GF_SECURITY_ADMIN_PASSWORD: "${GRAFANA_ADMIN_PASSWORD:-op://Developer/Grafana/Admin/password}"
      GF_USERS_ALLOW_SIGN_UP: "false"
      # Server
      GF_SERVER_ROOT_URL: "https://grafana.localhost"
      GF_SERVER_DOMAIN: "grafana.localhost"
      # Auth
      GF_AUTH_ANONYMOUS_ENABLED: "false"
      # Paths
      GF_PATHS_PROVISIONING: "/etc/grafana/provisioning"
      # Feature toggles
      GF_FEATURE_TOGGLES_ENABLE: "traceqlEditor tempoSearch tempoBackendSearch tempoApmTable traceToProfiles tracesEmbeddedFlameGraph"
      # Plugins
      GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel"
    volumes:
      - ${XDG_CONFIG_HOME:-$HOME/.config}/docker/config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ${XDG_DATA_HOME:-$HOME/.local/share}/grafana:/var/lib/grafana
    expose:
      - "3000"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --spider -q http://localhost:3000/api/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 128M

  # =============================================================================
  # Grafana Tempo - Distributed Tracing Backend
  # =============================================================================
  #
  # Tempo is a high-volume, minimal-dependency distributed tracing backend.
  # It only requires object storage to operate and is deeply integrated with
  # Grafana, Prometheus, and Loki.
  #
  # Features:
  #   - Cost-effective (only indexes trace IDs)
  #   - Multi-protocol ingestion (OTLP, Jaeger, Zipkin, OpenCensus)
  #   - TraceQL for advanced trace queries
  #   - Service graph generation
  #   - Span metrics (RED metrics from traces)
  #
  # Ingest Protocols:
  #   - OTLP gRPC: 4317
  #   - OTLP HTTP: 4318
  #   - Jaeger Thrift: 14268
  #   - Jaeger gRPC: 14250
  #   - Zipkin: 9411
  #
  # Query Endpoints:
  #   - HTTP API: 3200
  #   - TraceQL: 3200
  #
  # Usage:
  #   docker-compose -f tempo.yaml up
  #   docker-compose --profile observability up
  #
  # =============================================================================

  tempo:
    image: grafana/tempo:2.5.0
    hostname: tempo
    container_name: tempo
    profiles: ["o11y-tracing", "o11y"]
    user: "10001:10001"
    networks:
      - backend # For service access
      - data-tier # For storage backends
    restart: unless-stopped
    command: -config.file=/etc/tempo/tempo.yaml
    volumes:
      - ${XDG_CONFIG_HOME:-$HOME/.config}/docker/config/tempo:/etc/tempo:ro
      - ${XDG_DATA_HOME:-$HOME/.local/share}/tempo:/var/tempo
    expose:
      - "3200" # Tempo HTTP API
      - "4317" # OTLP gRPC
      - "4318" # OTLP HTTP
      - "9411" # Zipkin
      - "14268" # Jaeger Thrift HTTP
      - "14250" # Jaeger gRPC
    healthcheck:
      test:
        ["CMD-SHELL", "wget --spider -q http://localhost:3200/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 256M
